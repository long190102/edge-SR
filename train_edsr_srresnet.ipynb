{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import thư viện"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:23:58.495030Z","iopub.status.busy":"2024-09-25T12:23:58.494308Z","iopub.status.idle":"2024-09-25T12:24:03.729522Z","shell.execute_reply":"2024-09-25T12:24:03.728566Z","shell.execute_reply.started":"2024-09-25T12:23:58.494992Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","import shutil\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.parallel import DataParallel\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torchvision.utils import save_image\n","import torchsummary\n","from tqdm import tqdm\n","from models.srresnet import *\n","from models.edsr import *\n","\n","import time\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.731452Z","iopub.status.busy":"2024-09-25T12:24:03.730941Z","iopub.status.idle":"2024-09-25T12:24:03.794823Z","shell.execute_reply":"2024-09-25T12:24:03.793839Z","shell.execute_reply.started":"2024-09-25T12:24:03.731417Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tạo Mô hình SR"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","# device = torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.797602Z","iopub.status.busy":"2024-09-25T12:24:03.797285Z","iopub.status.idle":"2024-09-25T12:24:03.821933Z","shell.execute_reply":"2024-09-25T12:24:03.821064Z","shell.execute_reply.started":"2024-09-25T12:24:03.797577Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["\n","# edsr.load_state_dict(torch.load('weight/best_edsr.pth', map_location=device))\n","# edsr.load_state_dict(torch.load('weight/best_edsrx4_orig_model.pth', map_location=device))\n","# edrn_sobel.load_state_dict(torch.load('weight/best_sobel_srx4_model.pth', map_location=device))\n","# edrn_canny.load_state_dict(torch.load('weight/best_canny_srx4_model.pth', map_location=device))\n","# srresnet.load_state_dict(torch.load('best_srresnet.pth', map_location=device))\n","# vdsr.load_state_dict(torch.load('weight/best_vdsr.pth', map_location=device))"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.824325Z","iopub.status.busy":"2024-09-25T12:24:03.823331Z","iopub.status.idle":"2024-09-25T12:24:03.833160Z","shell.execute_reply":"2024-09-25T12:24:03.832215Z","shell.execute_reply.started":"2024-09-25T12:24:03.824292Z"},"trusted":true},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, lr_dir, hr_dir, valid = False, scale=4):\n","        self.lr_files = sorted(os.listdir(lr_dir))\n","        self.hr_files = sorted(os.listdir(hr_dir))\n","        self.lr_dir = lr_dir\n","        self.hr_dir = hr_dir\n","        self.valid = valid\n","        self.scale = scale\n","    def __len__(self):\n","        return len(self.lr_files)\n","\n","    def __getitem__(self, idx):\n","        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_files[idx])).convert('RGB')\n","        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_files[idx])).convert('RGB')\n","        \n","        w, h = hr_image.size\n","        if self.valid:\n","            lr_image = lr_image.resize((w//self.scale, h//self.scale))\n","            \n","        transform = transforms.Compose([\n","            # transforms.ToPILImage(),\n","            transforms.ToTensor()\n","        ])\n","        \n","        lr_image = transform(lr_image)\n","        hr_image = transform(hr_image)\n","        return lr_image, hr_image"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Tạo Hyperparameter"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def calculate_psnr(img1, img2):\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    max_pixel = 1.0\n","    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","    return psnr.item()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:29.152867Z","iopub.status.busy":"2024-09-25T12:33:29.152523Z","iopub.status.idle":"2024-09-25T12:33:30.352211Z","shell.execute_reply":"2024-09-25T12:33:30.351285Z","shell.execute_reply.started":"2024-09-25T12:33:29.152842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 0/12500 [00:00<?, ?batch/s]/home/robot/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n","Epoch 1/24:   0%|          | 1/12500 [00:00<42:16,  4.93batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 4/12500 [00:00<21:47,  9.56batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 6/12500 [00:00<19:36, 10.62batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 10/12500 [00:00<18:09, 11.47batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 12/12500 [00:01<17:44, 11.73batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 16/12500 [00:01<17:10, 12.12batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 18/12500 [00:01<17:10, 12.11batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 22/12500 [00:01<17:00, 12.22batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 24/12500 [00:02<17:03, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 28/12500 [00:02<16:38, 12.49batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 30/12500 [00:02<16:46, 12.39batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 34/12500 [00:02<16:52, 12.32batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 36/12500 [00:03<17:03, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 40/12500 [00:03<16:45, 12.39batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 42/12500 [00:03<16:52, 12.31batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 46/12500 [00:03<16:59, 12.22batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 48/12500 [00:04<17:02, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 52/12500 [00:04<17:30, 11.85batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 54/12500 [00:04<17:29, 11.86batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 58/12500 [00:04<17:14, 12.02batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 60/12500 [00:05<17:09, 12.09batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 64/12500 [00:05<16:54, 12.25batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 66/12500 [00:05<16:52, 12.28batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 70/12500 [00:05<16:57, 12.21batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 72/12500 [00:06<17:01, 12.17batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 76/12500 [00:06<17:00, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 78/12500 [00:06<16:45, 12.36batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 82/12500 [00:06<16:47, 12.33batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 84/12500 [00:07<16:53, 12.25batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 88/12500 [00:07<16:53, 12.25batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 90/12500 [00:07<16:45, 12.35batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 94/12500 [00:07<16:58, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 96/12500 [00:08<16:58, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 100/12500 [00:08<16:58, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 102/12500 [00:08<16:38, 12.41batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 106/12500 [00:08<16:47, 12.30batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 108/12500 [00:08<16:49, 12.27batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 112/12500 [00:09<17:17, 11.94batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 114/12500 [00:09<16:52, 12.24batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 118/12500 [00:09<16:55, 12.20batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 120/12500 [00:09<16:58, 12.15batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 124/12500 [00:10<17:04, 12.08batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 126/12500 [00:10<16:58, 12.15batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 130/12500 [00:10<16:50, 12.24batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 132/12500 [00:10<16:44, 12.31batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 136/12500 [00:11<16:54, 12.18batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   1%|          | 139/12500 [00:11<17:08, 12.02batch/s]"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n","torch.Size([16, 3, 48, 48])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m optim_srresnet\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m     outputs_srresnet \u001b[38;5;241m=\u001b[39m \u001b[43msrresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     loss_srresnet \u001b[38;5;241m=\u001b[39m criterion(outputs_srresnet, hr_images)\n\u001b[1;32m     84\u001b[0m psnr_srresnet \u001b[38;5;241m=\u001b[39m calculate_psnr(outputs_srresnet, hr_images)\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Desktop/pcb/models/srresnet.py:97\u001b[0m, in \u001b[0;36mSRResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_input(x))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#residual = out.clone()\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_mid(out)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn:\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Desktop/pcb/models/srresnet.py:32\u001b[0m, in \u001b[0;36m_Residual_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(output)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn:\n\u001b[0;32m---> 32\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(output,x)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:156\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    158\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from torch.amp import autocast, GradScaler\n","scaler = GradScaler()\n","\n","# Khởi tạo dataset và dataloader\n","for scale in [2, 3, 4]:\n","    print(scale)\n","    train_lr_dir = f'dataset/Train/LR_{scale}'\n","    train_hr_dir = 'dataset/Train/HR'\n","    valid_lr_dir = 'dataset/Test/HR'\n","    valid_hr_dir = 'dataset/Test/HR'\n","    train_dataset = ImageDataset(train_lr_dir, train_hr_dir, scale=scale)\n","    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","    valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir, scale=scale, valid = True)\n","    valid_loader = DataLoader(valid_dataset)\n","\n","    # Khởi tạo loss function\n","    criterion = nn.MSELoss()\n","    edsr = EDSR(scale=scale).to(device)\n","    srresnet = SRResNet(scale=scale).to(device)\n","    \n","    # Khởi tạo optimizers, schedulers cho từng mô hình\n","    optim_edsr = optim.Adam(edsr.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","    scheduler_edsr = optim.lr_scheduler.StepLR(optim_edsr, step_size=10**5, gamma=0.5)\n","\n","    optim_srresnet = optim.Adam(srresnet.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","    scheduler_srresnet = optim.lr_scheduler.StepLR(optim_srresnet, step_size=10**5, gamma=0.5)\n","    \n","    num_epochs = 24\n","\n","    best_psnr_edsr = float('-inf')\n","    best_psnr_srresnet = float('-inf')\n","\n","    torch.cuda.empty_cache()\n","\n","    losses_edsr = []\n","    losses_srresnet = []\n","\n","    avg_psnr_edsr = []\n","    avg_psnr_srresnet = []\n","\n","    val_avg_psnr_edsr = []\n","    val_avg_psnr_srresnet = []\n","\n","    patience = 5\n","    epochs_no_improve = 0\n","    log_file = open('outputs/train_log/edsr_srresnet.txt', 'a')\n","\n","    for epoch in range(num_epochs):\n","        edsr.train()\n","        srresnet.train()\n","\n","        epoch_loss_edsr, psnr_values_edsr = 0, 0\n","        epoch_loss_srresnet, psnr_values_srresnet = 0, 0\n","\n","        start_time = time.time()\n","        torch.cuda.empty_cache()\n","        # Training loop for each model\n","        for i, (lr_images, hr_images) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n","            lr_images = lr_images.to(device)\n","            hr_images = hr_images.to(device)\n","\n","            # # Train EDSR model\n","            optim_edsr.zero_grad()\n","            with autocast(device_type='cuda'):\n","                outputs_edsr = edsr(lr_images)\n","                print(lr_images.shape)\n","                loss_edsr = criterion(outputs_edsr, hr_images)\n","            psnr_edsr = calculate_psnr(outputs_edsr, hr_images)\n","\n","            scaler.scale(loss_edsr).backward()\n","            scaler.step(optim_edsr)\n","            scaler.update()\n","            scheduler_edsr.step()\n","\n","            epoch_loss_edsr += loss_edsr.item()\n","            \n","            psnr_values_edsr += psnr_edsr\n","            # Train SRResNet model\n","            optim_srresnet.zero_grad()\n","            with autocast(device_type='cuda'):\n","                outputs_srresnet = srresnet(lr_images)\n","                loss_srresnet = criterion(outputs_srresnet, hr_images)\n","            psnr_srresnet = calculate_psnr(outputs_srresnet, hr_images)\n","\n","            scaler.scale(loss_srresnet).backward()\n","            scaler.step(optim_srresnet)\n","            scaler.update()\n","            scheduler_srresnet.step()\n","\n","            epoch_loss_srresnet += loss_srresnet.item()\n","            psnr_values_srresnet += psnr_srresnet\n","\n","\n","        # Average losses and PSNRs\n","        avg_epoch_loss_edsr = epoch_loss_edsr / len(train_loader)\n","        avg_psnr_edsr_epoch = psnr_values_edsr / len(train_loader)\n","        losses_edsr.append(avg_epoch_loss_edsr)\n","        avg_psnr_edsr.append(avg_psnr_edsr_epoch)\n","\n","        avg_epoch_loss_srresnet = epoch_loss_srresnet / len(train_loader)\n","        avg_psnr_srresnet_epoch = psnr_values_srresnet / len(train_loader)\n","        losses_srresnet.append(avg_epoch_loss_srresnet)\n","        avg_psnr_srresnet.append(avg_psnr_srresnet_epoch)\n","\n","        # Validation for all models\n","        edsr.eval()\n","        srresnet.eval()\n","    \n","\n","        val_psnr_edsr, val_psnr_srresnet = 0, 0\n","\n","        with torch.no_grad():\n","            for (lr_images, hr_images) in valid_loader:\n","                lr_images = lr_images.cuda()\n","                hr_images = hr_images.cuda()\n","\n","                # # Validate EDSR\n","                outputs_edsr = edsr(lr_images)\n","                psnr_edsr = calculate_psnr(outputs_edsr, hr_images)\n","                val_psnr_edsr += psnr_edsr\n","\n","                # Validate SRResNet\n","                outputs_srresnet = srresnet(lr_images)\n","                psnr_srresnet = calculate_psnr(outputs_srresnet, hr_images)\n","                val_psnr_srresnet += psnr_srresnet\n","\n","        val_avg_psnr_edsr_epoch = val_psnr_edsr / len(valid_loader)\n","        val_avg_psnr_edsr.append(val_avg_psnr_edsr_epoch)\n","\n","        val_avg_psnr_srresnet_epoch = val_psnr_srresnet / len(valid_loader)\n","        val_avg_psnr_srresnet.append(val_avg_psnr_srresnet_epoch)\n","\n","    \n","        # Save best model\n","        if val_avg_psnr_edsr_epoch > best_psnr_edsr:\n","            best_psnr_edsr = val_avg_psnr_edsr_epoch\n","            torch.save(edsr.state_dict(), f'outputs/weight_sr/x{scale}/best_edsr.pth')\n","            print(f\"Saved EDSRR model with PSNR {best_psnr_edsr:.4f}\")\n","        if val_avg_psnr_srresnet_epoch > best_psnr_srresnet:\n","            best_psnr_srresnet = val_avg_psnr_srresnet_epoch\n","            torch.save(srresnet.state_dict(), f'outputs/weight_sr/x{scale}/best_srresnet.pth')\n","            print(f\"Saved SRResNet model with PSNR {best_psnr_srresnet:.4f}\")\n","\n","        torch.save(edsr.state_dict(), f'outputs/path/edsr_{epoch}.pth')\n","        torch.save(srresnet.state_dict(), f'outputs/path/srresnet_{epoch}.pth')\n","        \n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] completed: EDSR Loss: {avg_epoch_loss_edsr:.4f}, PSNR: {avg_psnr_edsr_epoch:.4f}, Validation PSNR: {val_avg_psnr_edsr_epoch:.4f},\"\n","            \"SRResNEt Loss: {avg_epoch_loss_srresnet:.4f}, PSNR: {avg_psnr_srresnet_epoch:.4f}, Validation PSNR: {val_avg_psnr_srresnet_epoch:.4f}\")\n","\n","        log_file.write(f\"Epoch {epoch+1}:  EDSR PSNR: {avg_psnr_edsr_epoch:.4f}, Validation PSNR: {val_avg_psnr_edsr_epoch:.4f}\\n\")\n","        log_file.write(f\"              SRResNet PSNR: {avg_psnr_srresnet_epoch:.4f}, Validation PSNR: {val_avg_psnr_srresnet_epoch:.4f}\\n\")\n","        \n","        log_file.flush()\n","\n","    log_file.close()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5414450,"sourceId":8989742,"sourceType":"datasetVersion"},{"datasetId":5671931,"sourceId":9356096,"sourceType":"datasetVersion"},{"datasetId":5764801,"sourceId":9478075,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
